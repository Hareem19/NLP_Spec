{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9eeefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79528293",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'spacy' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp\u001b[38;5;241m=\u001b[39mspacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'spacy' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c494cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp('Hello Hareem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b855677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99440acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello INTJ compound\n",
      "Hareem PROPN ROOT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5b4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp('Hello Hareem, How are     you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a54e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e547cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello INTJ compound\n",
      "Hareem PROPN nsubj\n",
      ", PUNCT punct\n",
      "How SCONJ advmod\n",
      "are AUX ROOT\n",
      "     SPACE dep\n",
      "you PRON nsubj\n",
      "? PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd13a321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(doc[1].dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "516a56fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8c4a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70159136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bbb3d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "251ac084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].is_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "535c412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Xxxxx\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].text,doc[0].shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "704784a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2072640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the paragraph\n",
    "text =(\"\"\"SpaCy is a powerful natural language processing library.It provides tools for text analysis and understanding. You can perform tasks like tokenization, POS tagging, and NER.\n",
    "SpaCy is widely used in various NLP applications.It's an essential tool for language processing.\"\"\")\n",
    "doc = nlp(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a029c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy is a powerful natural language processing library.\n",
      "It provides tools for text analysis and understanding.\n",
      "You can perform tasks like tokenization, POS tagging, and NER.\n",
      "\n",
      "SpaCy is widely used in various NLP applications.\n",
      "It's an essential tool for language processing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenization\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8af7bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40ff3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr='\"we\\'re moving to L.A.!\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3023a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "55c6c7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"|we|'re|moving|to|L.A.|!|\"|"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bd9724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b78cfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"|we|'re|moving|to|L.A.|!|\"|"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f7fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "12ae919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(\"hong kong has a Apple store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2862df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hong kong GPE Countries, cities, states\n",
      "Apple ORG Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.label_, str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cc389d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(\"hong kong has rolex store, daniel store, Hareem plaza. Umama is a good girl. Pakistans flag has a moon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "74888ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hong kong GPE Countries, cities, states\n",
      "rolex store PERSON People, including fictional\n",
      "daniel store PERSON People, including fictional\n",
      "Hareem PERSON People, including fictional\n",
      "Pakistans NORP Nationalities or religious or political groups\n"
     ]
    }
   ],
   "source": [
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_, str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e2c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
